# -*- coding: utf-8 -*-
"""Sppech to Text.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KMmFCyWZlX_gvrs-gvS4O_I2ar-LggVz
"""

!pip install faiss-cpu sentence-transformers langid transformers torch --quiet

import faiss
import numpy as np
import pandas as pd
import langid
from sentence_transformers import SentenceTransformer
from transformers import MarianMTModel,MarianTokenizer,pipeline

faq_data = {
    "question": [
        "What is the last date for fee submission?",
        "How to apply for a scholarship?",
        "Where can I find the timetable?",
        "Who should I contact for hostel issues?",
        "How to get my ID card reissued?"
    ],
    "answer": [
        "The last date for fee submission is 30th September.",
        "You can apply for a scholarship via the student portal under 'Scholarship Section'.",
        "The timetable is available on the official college website.",
        "For hostel issues, please contact the warden in the hostel office.",
        "For ID card reissue, visit the admin office with a request form and ID proof."
    ]
}
faq_df = pd.DataFrame(faq_data)

embedder = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")

generator = pipeline("text-generation", model="distilgpt2", max_new_tokens=30)

src_lang = "Helsinki-NLP/opus-mt-hi-en"
tgt_lang = "Helsinki-NLP/opus-mt-en-hi"

trans_tokenizer_src = MarianTokenizer.from_pretrained(src_lang)
trans_model_src = MarianMTModel.from_pretrained(src_lang)

trans_tokenizer_tgt = MarianTokenizer.from_pretrained(tgt_lang)
trans_model_tgt = MarianMTModel.from_pretrained(tgt_lang)

def translate(text, tokenizer, model):
    inputs = tokenizer(text, return_tensors="pt", padding=True)
    translated = model.generate(**inputs)
    return tokenizer.decode(translated[0], skip_special_tokens=True)

corpus = faq_df["question"].tolist()
corpus_embeddings = embedder.encode(corpus)
dim = corpus_embeddings.shape[1]
index = faiss.IndexFlatL2(dim)
index.add(np.array(corpus_embeddings, dtype="float32"))

def chatbot(query, k=1):
    lang, conf = langid.classify(query)
    print(f"[LangID] Detected: {lang} (conf={conf:.2f})")

    if lang != "en":
        query = translate(query, trans_tokenizer_src, trans_model_src)
        print(f"[Translation] To English: {query}")

    query_vec = embedder.encode([query])
    distances, indices = index.search(np.array(query_vec, dtype="float32"), k)
    base_answer = faq_df.iloc[indices[0][0]]["answer"]

    gen_input = f"Q: {query}\nA: {base_answer}\nBetter Answer:"
    gen_answer = generator(gen_input, num_return_sequences=1)[0]["generated_text"]

    return gen_answer

queries = [
    "When is the deadline to pay fees?",

    "I lost my ID card, what should I do?"
]

for q in queries:
    print(f"\nüë©‚Äçüéì User: {q}")
    print(f"ü§ñ Bot:  {chatbot(q)}\n")

queries = [
    "When is the deadline to pay fees?",

    "I lost my ID card, what should I do?"
]

